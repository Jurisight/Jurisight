{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q llama-index\n",
    "# %pip install -q transformers\n",
    "# %pip install -q accelerate\n",
    "# %pip install -q InstructorEmbedding\n",
    "# %pip install -U sentence-transformers\n",
    "# %pip install llama-index-llms-huggingface\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-embeddings-instructor\n",
    "# %pip install -q pinecone-client\n",
    "# %pip install llama-index-vector-stores-pinecone\n",
    "# %pip install llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\envs\\jurisight\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import Settings\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Groq(model=\"llama3-8b-8192\", api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"float16\", low_cpu_mem_usage=True)\n",
    "# Settings.llm = HuggingFaceLLM(\n",
    "#     context_window=2048,\n",
    "#     max_new_tokens=512,\n",
    "#     generate_kwargs={\"temperature\": 0.1, \"do_sample\": False},\n",
    "#     tokenizer_name=tokenizer,\n",
    "#     model_name=model,\n",
    "#     tokenizer_kwargs={\"max_length\": 2048},\n",
    "#     model_kwargs={\"torch_dtype\": torch.float16}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=\"pcsk_2965Hx_QAS6BANzXyQ4e4e5JhmLFY9EBcbs15P9yEXKbSej7Yr4xkCgbb4nK5763pAxeN6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = 'llamaindex'\n",
    "# if index_name not in pc.list_indexes():\n",
    "#     pc.create_index(\n",
    "#         name=index_name,\n",
    "#         dimension=768,\n",
    "#         metric='cosine',\n",
    "#         spec=ServerlessSpec(\n",
    "#             cloud=\"aws\",\n",
    "#             region=\"us-east-1\"\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deletion_protection': 'enabled',\n",
       " 'dimension': 768,\n",
       " 'host': 'llamaindex-7ekilca.svc.aped-4627-b74a.pinecone.io',\n",
       " 'metric': 'cosine',\n",
       " 'name': 'llamaindex',\n",
       " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       " 'status': {'ready': True, 'state': 'Ready'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index = pc.Index(\"llamaindex\")\n",
    "pc.describe_index(\"llamaindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = SimpleDirectoryReader(\"Rag_data\").load_data()\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex.from_documents(documents, storage_context=storage_context, show_progress=True)\n",
    "# index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A writ petition is a legal instrument that enables an individual or a group to approach the court for enforcement of their constitutional or legal rights. It is a powerful tool for seeking redressal of grievances and ensuring social justice. In India, the Supreme Court and High Courts have the power to entertain writ petitions under Articles 32 and 226 of the Constitution, respectively. A writ petition can be filed in the form of a letter, and the court may treat it as a writ petition if it is addressed by an aggrieved person or a public spirited individual or a social action group for enforcement of the constitutional or legal rights of a person. The court may also consider it expedient to treat a letter as a writ petition in the interests of justice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Short note on writ petitions\")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jurisight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
